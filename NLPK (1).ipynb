{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a6055c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13836\\3469633215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b6b2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug=pd.read_table(r\"C:\\Users\\Vihang\\OneDrive\\Desktop\\drugsCom_raw (1).tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b967bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datatype of columns\n",
    "\n",
    "drug.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d495b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the data contains any NULL values\n",
    "\n",
    "drug.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug['condition'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67121c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = ['Depression','High Blood Pressure','Diabetes, Type 2']\n",
    "drug1=drug[drug['condition'].isin(condition1)]\n",
    "drug1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date in to date time format\n",
    "#drug1['date'] = pd.to_datetime(drug1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65372bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.loc[drug1['rating'] == 1, :]['drugName'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of unique values in drugName\n",
    "print(drug1['drugName'].nunique())\n",
    "\n",
    "#check number of unique values in condition\n",
    "print(drug1['condition'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bargraph to check top 10 conditions\n",
    "plt.figure(figsize=(8,6))\n",
    "conditions = drug1['condition'].value_counts(ascending = False).head(10)\n",
    "\n",
    "plt.bar(conditions.index,conditions.values)\n",
    "plt.title('Top-10 Conditions',fontsize = 20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89138cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bargraph to check bottom 10 conditions\n",
    "plt.figure(figsize=(8,6))\n",
    "conditions_bottom = drug1['condition'].value_counts(ascending = False).tail(10)\n",
    "\n",
    "plt.bar(conditions_bottom.index,conditions_bottom.values)\n",
    "plt.title('Bottom-10 Conditions',fontsize = 10)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2938ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bargraph to check top 10 drugName\n",
    "plt.figure(figsize=(8,6))\n",
    "drugName_top = drug1['drugName'].value_counts(ascending = False).head(10)\n",
    "\n",
    "plt.bar(drugName_top.index,drugName_top.values,color='blue')\n",
    "plt.title('drugName Top-10',fontsize = 20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a bargraph to check top  10 drugName\n",
    "plt.figure(figsize=(8,6))\n",
    "drugName_bottom = drug1['drugName'].value_counts(ascending = False).tail(10)\n",
    "\n",
    "plt.bar(drugName_bottom.index,drugName_bottom.values,color='blue')\n",
    "plt.title('drugName Bottom-10',fontsize = 20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_ = drug1['rating'].value_counts().sort_values(ascending=False).reset_index().\\\n",
    "                    rename(columns = {'index' :'rating', 'rating' : 'counts'})\n",
    "ratings_['percent'] = 100 * (ratings_['counts']/drug.shape[0])\n",
    "print(ratings_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c602078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Parameter\n",
    "sns.set(font_scale = 1.2)\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "\n",
    "#let's plot and check\n",
    "sns.barplot(x = ratings_['rating'], y = ratings_['percent'],order = ratings_['rating'])\n",
    "plt.title('Percent of ratings',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4395da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a distplot of usefulCount\n",
    "sns.distplot(drug1['usefulCount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d58bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the descriptive summary\n",
    "sns.boxplot(y = drug1['usefulCount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881517fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the number of drugs/condition\n",
    "drug1.groupby('condition')['drugName'].nunique().sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee956726",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8446ad",
   "metadata": {},
   "source": [
    "# EDA after removing noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the number of drugs present in our dataset condition wise\n",
    "conditions_data = drug1.groupby('condition')['drugName'].nunique().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Setting the Parameter\n",
    "condition_data_top_10 = conditions_data.head(10)\n",
    "sns.set(font_scale = 1.2)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "sns.barplot(x = condition_data_top_10.index, y = condition_data_top_10.values)\n",
    "plt.title('Top-10 Number of drugs per condition',fontsize=20)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6621bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the words cloud for the reviews \n",
    "\n",
    "# most popular drugs\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wordcloud = WordCloud(background_color = 'black', stopwords = stopwords, width = 1200, height = 800).generate(str(drug['drugName']))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.title('Word Cloud - Drug Names', fontsize = 25)\n",
    "print(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a donut chart to represent share of each ratings\n",
    "\n",
    "size = [68005, 46901, 36708, 25046, 12547, 10723, 8462, 6671]\n",
    "colors = ['pink', 'cyan', 'maroon',  'magenta', 'orange', 'navy', 'lightgreen', 'yellow']\n",
    "labels = \"10\", \"1\", \"9\", \"8\", \"7\", \"5\", \"6\", \"4\"\n",
    "\n",
    "my_circle = plt.Circle((0, 0), 0.7, color = 'white')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.pie(size, colors = colors, labels = labels, autopct = '%.2f%%')\n",
    "plt.axis('off')\n",
    "plt.title('Pie Chart Representation of Ratings', fontsize = 25)\n",
    "p = plt.gcf()\n",
    "plt.gca().add_artist(my_circle)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A countplot of the ratings so we can see the distribution of the ratings\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "sns.set(font_scale = 1.4, style = 'darkgrid')\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "sns_1 = sns.countplot(drug1['rating'], palette = 'spring', order = list(range(10, 0, -1)), ax = ax[0])\n",
    "sns_2 = sns.distplot(drug1['rating'], ax = ax[1])\n",
    "sns_1.set_title('Count of Ratings')\n",
    "sns_1.set_xlabel(\"Rating\")\n",
    "\n",
    "sns_2.set_title('Distribution of Ratings')\n",
    "sns_2.set_xlabel(\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca51deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most popular drugs\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wordcloud = WordCloud(background_color = 'lightblue', stopwords = stopwords, width = 1200, height = 800).generate(str(drug1['review']))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.title('WORD CLOUD OF REVIEWS', fontsize = 25)\n",
    "print(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n",
    "# let's make a new column review sentiment \n",
    "\n",
    "drug1.loc[(drug1['rating'] >= 5), 'Review_Sentiment'] = 1\n",
    "drug1.loc[(drug1['rating'] < 5), 'Review_Sentiment'] = 0\n",
    "\n",
    "drug1['Review_Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pie chart to represent the sentiments of the patients\n",
    "\n",
    "size = [161491, 53572]\n",
    "colors = ['lightblue', 'navy']\n",
    "labels = \"Positive Sentiment\",\"Negative Sentiment\"\n",
    "explode = [0, 0.1]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.pie(size, colors = colors, labels = labels, explode = explode, autopct = '%.2f%%')\n",
    "plt.axis('off')\n",
    "plt.title('Pie Chart Representation of Sentiments', fontsize = 25)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f389ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making Words cloud for the postive sentiments\n",
    "\n",
    "positive_sentiments = \" \".join([text for text in drug1['review'][drug1['Review_Sentiment'] == 1]])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(background_color = 'black', stopwords = stopwords, width = 1200, height = 800).generate(positive_sentiments)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.title('Word Cloud of Positive Reviews', fontsize = 30)\n",
    "print(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making wordscloud for the Negative sentiments\n",
    "\n",
    "negative_sentiments = \" \".join([text for text in drug1['review'][drug1['Review_Sentiment'] == 0]])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(background_color = 'black', stopwords = stopwords, width = 1200, height = 800).generate(negative_sentiments)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "plt.title('Word Cloud of Negative Reviews', fontsize = 30)\n",
    "print(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ce1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3faf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drug1.drop(['Unnamed: 0','drugName','rating','date','usefulCount'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827aed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# porter = PorterStemmer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ece896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lemmatizer.lemmatize(\"sportingly\"))\n",
    "print(lemmatizer.lemmatize(\"very\"))\n",
    "print(lemmatizer.lemmatize(\"troubled\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57073b05",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_clean(review): \n",
    "    # changing to lower case\n",
    "    lower = review.str.lower()\n",
    "    \n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n",
    "    \n",
    "    # Removing all the special Characters\n",
    "    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    \n",
    "    # Removing all the non ASCII characters\n",
    "    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n",
    "    \n",
    "    # Replacing Two or more dots with one\n",
    "    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1['review_clean'] = review_clean(drug1['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9da95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import nltk\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Removing the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "drug1['review_clean'] = drug1['review_clean'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the word stems using the Snowball Stemmer\n",
    "Snow_ball = SnowballStemmer(\"english\")\n",
    "drug1['review_clean'] = drug1['review_clean'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap of the features engineered\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "sns.set(font_scale = 1.2)\n",
    "corr = drug1.select_dtypes(include = 'int64').corr()\n",
    "sns_ = sns.heatmap(corr, annot = True, cmap = 'Wistia')\n",
    "plt.setp(sns_.get_xticklabels(), rotation = 45);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979631ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(review):\n",
    "    # Sentiment polarity of the reviews\n",
    "    pol = []\n",
    "    for i in review:\n",
    "        analysis = TextBlob(i)\n",
    "        pol.append(analysis.sentiment.polarity)\n",
    "    return pol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1['sentiment'] = sentiment(drug1['review'])\n",
    "drug1['sentiment_clean'] = sentiment(drug1['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the reviews without removing the stop words and using snowball stemmer\n",
    "drug1['review_clean_ss'] = review_clean(drug1['review'])\n",
    "drug1['sentiment_clean_ss'] = sentiment(drug1['review_clean_ss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1 = drug1.dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word count in each review\n",
    "drug1['count_word']=drug1[\"review_clean_ss\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count \n",
    "drug1['count_unique_word']=drug1[\"review_clean_ss\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "#Letter count\n",
    "drug1['count_letters']=drug1[\"review_clean_ss\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#punctuation count\n",
    "drug1[\"count_punctuations\"] = drug1[\"review\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#upper case words count\n",
    "drug1[\"count_words_upper\"] = drug1[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "#title case words count\n",
    "drug1[\"count_words_title\"] = drug1[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "#Number of stopwords\n",
    "drug1[\"count_stopwords\"] = drug1[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "\n",
    "#Average length of the words\n",
    "drug1[\"mean_word_len\"] = drug1[\"review_clean_ss\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a117166",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3849469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label Encoding Drugname and Conditions\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_feat = {}\n",
    "for feature in ['drugName', 'condition']:\n",
    "    label_encoder_feat[feature] = LabelEncoder()\n",
    "    drug1[feature] = label_encoder_feat[feature].fit_transform(drug1[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e11470",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096691ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe22134",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug1['drugName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88993cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drug1.drop(['Unnamed: 0','drugName','rating','date','usefulCount'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ab17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=drug1['review']\n",
    "y=drug1['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc125845",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = drug1[['condition', 'usefulCount', 'sentiment',\n",
    "                   'sentiment_clean_ss', 'count_word', 'count_unique_word', 'count_letters',\n",
    "                   'count_punctuations', 'count_words_upper', 'count_words_title',\n",
    "                   'count_stopwords', 'mean_word_len']]\n",
    "\n",
    "target = drug1['Review_Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\n",
    "print (\"The Train set size \", X_train.shape)\n",
    "print (\"The Test set size \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476fa50",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a15101",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d167d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools # confusion matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b22f4",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbfe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "Output: GaussianNB(priors=None, var_smoothing=1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b884a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_NB = classifier.predict(X_test)\n",
    "y_pred_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a053037",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_NB = confusion_matrix(y_test, y_pred_NB) \n",
    "cm_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_NB, classes=['Depression','Diabetes, Type 2','High Blood Pressure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_NB = 2566 #True Positives \n",
    "TN_NB = 457 #True Negatives \n",
    "FP_NB = 543 #False Positives \n",
    "FN_NB = 618 #False Negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7931f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_NB = (TP_NB + TN_NB) / (TP_NB + TN_NB + FP_NB + FN_NB) \n",
    "Accuracy_NB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_NB = TP_NB / (TP_NB + FP_NB)\n",
    "Precision_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_NB = TP_NB / (TP_NB + FN_NB)\n",
    "Recall_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_Score_NB = 2 * Precision_NB * Recall_NB / (Precision_NB + Recall_NB)\n",
    "F1_Score_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b3d0e",
   "metadata": {},
   "source": [
    "# PassiveAggressiveClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc669b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
    "\n",
    "passive = PassiveAggressiveClassifier()\n",
    "passive.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124efcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = passive.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_PA = confusion_matrix(y_test, pred) \n",
    "cm_PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d555b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_PA, classes=['Depression','Diabetes, Type 2','High Blood Pressure'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_PA = 566 #True Positives \n",
    "TN_PA = 981 #True Negatives \n",
    "FP_PA = 2543 #False Positives \n",
    "FN_PA = 981 #False Negatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345046f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C= .1, kernel='linear', gamma= 1)\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a03903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "score_svm = metrics.accuracy_score(y_test, pred)\n",
    "score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9816e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = [ Accuracy_NB,score,score_svm]\n",
    "Methods = [  'Naive_Bayes', 'Passive_Aggressive','SVM']\n",
    "Accuracy_pos = np.arange(len(Methods))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(Accuracy_pos, Accuracy)\n",
    "plt.xticks(Accuracy_pos, Methods)\n",
    "plt.title('comparing the accuracy of each model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename =open(\"finalized_model.pkl\",mode=\"wb\") \n",
    "pickle.dump(classifier, filename)\n",
    "filename.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ea1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75071b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
